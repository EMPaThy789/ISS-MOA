\chapter{Evaluation}
\label{chapter:Evaluation}
Evaluation was done using MOA's Evaluate Prequential. The incremental nature and potential for change in the stream makes a distinct training and test set not straightforwardly achievable. The possibility of change means that the training and test set could potentially reflect different concepts and would require explicit change adaptation of the test set. Examples in the stream could also be scarce and taking out examples to form distinct sets potentially weakens training. To address these problem, we prequentially evaluate; first making a prediction on the arriving example, then using it for training. This allows us to use the same example both for testing and training without the training affecting the test result.

\section{Hardware and software}
As mentioned previously, all implementation was done using Java using the open source MOA framework.

Experiments were conducted on a Mac mini 2010 running OS X 10.9.5 (13F1911) with a 2.4 Ghz Intel Core 2 Duo, 8 GB of DDR3 RAM running at 1067 MHz and a NVIDIA GeForce 320M 256MB.

The JVM used was java SE Runtime Environment version 1.8.0\_102.

\section{Data sources}
\label{chapter:Evaluation:DataSources}

While there exists copious amounts of data available on the internet, finding stream data for testing and evaluation was surprisingly difficult. Stream mining being a relatively new field of study meant that publicly available stream datasets were difficult to find. Utilising scrapers introduces new problems such as how labels can be obtained for examples. Manually labelling data is time consuming and tedious while automated labelling would expand the project's scope greatly. Ethical and privacy issues surrounding directly scraping data online were also not something we wanted to be involved with. As a result, evaluation was mostly done using synthetic data streams created by various data generators.

\subsection*{Parameters}
Parameter settings for experiments were kept as similar as possible:
\begin{itemize}
\item
We used a window size of 1000 examples with a $k$ of 10 for kNN search.

\item
The number of features $f$ to be kept for subset selection was variable depending on the data source. For almost all experiments, a $f$ of 10 was used unless otherwise specified. For data streams with less than 10 features, all features were selected for feature selection. 

\item For experiments where hill climbing was enabled, the $f$ parameter is instead an upper bound for the number of size of the subset and how many features are ranked by the ranking function. $f$ was set to 50 which in most cases covers all features in the stream as most generators had less than 50 features total.

\item A decay factor of 0.1 was used for the accuracy estimation counts.

\item The re-ranking interval was set to 1000.

\item A hill climbing window of 2 was used for all experiments where hill climbing subset size selection was enabled, unless otherwise specified.

\item All generators were run over 500,000 examples with samples taken at intervals of 10,000 examples.

\item All generators used the default random seed of 1.

\item Generators in experiments used the default settings in MOA unless otherwise stated.
\end{itemize}

\subsection{SEA generator}
This is a simple generator which generates a problem with 3 attributes and 3 classes. Attributes are numeric between 0 and 10 and only two attributes are relevant \citep{SEA}.

\subsection{Random tree generator}
This is a tree based generator which constructs a decision tree by choosing attributes at random to split, and assigning random class labels to each leaf. After the tree has been constructed, examples are generated by assigning uniformly distributed random values to attributes and traversing the decision tree to get a class value \citep{Domingos:2000:MHD:347090.347107}. A tree of max depth 10 with 5 relevant nominal features and 5 relevant numeric features (the default parameters in MOA) was used to generate data for the purposes of our experiments.

\subsection{LED generator}
The LED generator generates a problem of predicting the digit displayed on a 7-segment LED display. Each attribute is a binary nominal attribute. The generator allows for the inclusion of 17 irrelevant attributes and also the option to include arbitrary noise, which is implemented as a chance for attributes to be inverted.

\subsection{Waveform generator}
This is a generator which generates the problem of predicting one of three arbitrary waveform types. This stream contains 21 attributes, all of which are numeric.

\subsection{Hyperplane generator}
This is a generator which generates a problem of predicting the class of a rotating hyperplane. Default parameters for the generator in MOA were used to generate the data stream which contains 10 numeric features.

\subsection{Agrawal generator}
The Agrawal generator generates the problem of whether to give out a loan or not based on a borrower's various circumstances. The criteria of the loan is dependent on one of ten different pre-defined loan functions described in the paper \citet{Agrawal1993}. Different Agrawal functions (1, 2, and 3) were tested in experiments. This generator generates both numeric and nominal features.

\subsection{New Zealand road accident data}
One real life dataset used in our experiments was the New~Zealand road accidents dataset where the first driver's responsibility was classified based on a variety of attributes over a period of several years. The original data was prepared by \citet{NZROAD} at the New~Zealand GovHack 2015 event.

While the dataset is not necessarily representative of a real world data stream, it contains elements of a real world data stream such as missing attributes, and complex relationships between features.

A $f$ of 20 was selected for the experiments after trials with $f$ values of 10, 20 and 30.
 
\section{Conditional generator}
A new issue arose when working with generators. We found that existing generators in MOA were created mainly to test classification and regression problems without the problem of feature selection in mind. Many generators as a result contained no irrelevant attributes which essentially makes feature selection redundant on those generators. Generators that contained irrelevant attributes often tended to only generate one type of data (either all nominal or numeric) and did not have the ability to adjust the number of relevant or irrelevant features, or their overall relevance to the problem. To address these issues, we created a new stream generator for evaluation which allows for the number and type of relevant and irrelevant features to be specified.

At a high level, the conditional generator simulates a similar problem to the LED generator. Each class requires certain conditions to be met for the instance to be of that class, in this case attributes relevant to the class must be certain values. Unlike the LED generator which only generates nominal attributes, our new generator generates both nominal and numeric attributes, and supports sudden feature drifts. The new generator also allows us to specify the number of relevant and irrelevant features in the stream.


\subsection{Parameters}
The generator has several parameters which are required.
\begin{itemize}
\item Two separate parameters (one for nominal and one for numeric attributes) for the maximum number of relevant attributes that can be associated with a class.
\item Two separate parameters for the number of irrelevant attributes to include in the stream for nominal and numeric attributes.
\item The maximum number of values $v$ for nominal attributes
\item The maximum divisions $d$ that can be associated with a class. Divisions are used to generate the accepted numeric values and are explained in the next section.
\item The number of classes in the stream.
\item Whether or not to include sudden feature drift into the generator and if so, the interval $i$ for when drift occurs.
\end{itemize}

\subsection{Implementation}
On initialisation of the generator, each attribute is first assigns a type, either nominal or numeric. Numeric features have assigned with it a multiplication factor which is a constant which allows us to work using normalised values, subsequently multiplying the values of the feature by its corresponding multiplication factor to give the different numeric features different ranges. The generator then generates a stream-concept data structure containing information on the indices of relevant and irrelevant attributes, and an array of a classification-class data structure, one for each class. 

The classification-class data structure contains the indices of features relevant to the given class that it is associated with and the values for those attributes which are accepted. Each class is associated with a random number of relevant nominal attributes and numeric features. The number of features relevant to the class is randomly generated and bounded by user entered parameters. The relevant and irrelevant attributes are assigned to random indices to avoid biases which could occur due to the attributes' ordering. Indices of relevant attributes are stored in two arrays dependent on the type of the attribute (nominal or numeric).

To assign relevant features to a class, the generator generates a random number $r$ between 1 and the maximum number of relevant features; it then traverses the relevant features array (either the nominal or numeric array) in the stream-concept data structure and associates the first $r$ number of features in the relevant feature array with the class. For example, a class with 5 relevant nominal features out of a maximum of 10 relevant nominal attributes will be associated with the first 5 features in the relevant nominal attributes array. A class with 3 relevant nominal features out of a maximum of 10 relevant nominal features for a class will be associated with the first 3 features in the relevant nominal attributes array. This is intended to give more importance to certain attributes and less to others.

\begin{algorithm}[h]
    \caption{Generating stream concept}
    \label{generateStreamConcept}
    \textbf{Input:} \\ 
    $U$ Maximum number of relevant numeric features \\
    $O$ Maximum number of relevant nominal features \\
    $D$ Maximum number divisions for a relevant numeric features \\
    $V$ Maximum number of values for a nominal feature\\
    $C$ Number of classes \\
    $I$ Array with information on type of feature (nominal/numeric) at index \\
    \textbf{Variables:}\\ 
    $a$ Array of size $U$ containing indices of relevant numeric attribute \\
    $b$ Array of size $O$ containing indices of relevant nominal attribute \\
    $u$ Temp variable used to store number of numeric features associated with a class\\
    $o$ Temp variable used to store number of nominal features associated with a class\\
    $r$ Data structure containing the accepted ranges for individual numeric features for each class\\
    $v$ Data structure containing the accepted values for individual nominal features for each class\\
    \textbf{Output:}\\ New Stream Concept \\
    \begin{algorithmic}[1] % The number tells where the line numbering should start
		
        \Procedure{GenerateConcept}{$U,O,D,V,C,I$}
            \For{Each $U$}
            \State add random numeric attribute to $a$ from $i$
            \EndFor
            
            \For{Each $O$}
            \State add random nominal attribute to $b$ from $i$
            \EndFor
            
            \For{Each $C$}
            	\State $u \gets$ random number between 1 and U
            	\State Associate first $u$ features in $a$ with current class
                \For{Each $u$}
                	\State Assign a random number of accepted ranges between 1 and $D/2$ to current feature
                \EndFor
                
            	\State $o \gets$ random number between 1 and O
            	\State Associate first $o$ features in $b$ with current class
                \For{Each $o$}
                	\State Assign a random number of accepted values between 1 and $V$ to current feature
                \EndFor
            \EndFor
            \State \Return Data structure containing $a$,$b$,$r$,$v$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

To generate the accepted values of an attribute for a given class, the generator first looks at the attributes type. A numeric attribute is assigned a random number of divisions (between 1 to $d$) at random intervals within the bounds of the attribute. Each range between the divisions are either accepted or rejected. The ranges are between 0 and 1. For Nominal attributes, each possible value for the nominal attribute is either accepted or rejected.\bigskip

Generation of an instance consists of generating a class value, then looking though the classification-class data structure associated with the class value and generating attributes values which satisfy the class' relevant attributes. A side effect of this method of class generation is the introduction of noise when a class has similar accepting values for the relevant feature as another class which causes the classes to overlap.

The generator also supports sudden feature drifts, where certain features suddenly cease to become useful to classification and others suddenly become relevant. Sudden feature drift occurs at a user set interval and is implemented by re-generating a new stream concept.\bigskip


\subsection{Evaluation parameters}
Due to the large amount of parameters available, experiments on the conditional generator were conducted on 6 datasets generated by the conditional generator with different parameters. A key point to note is that the maximum number of relevant features is an upper bound and not guaranteed to always be reached. In some cases some of the relevant features are only relevant to one class whereas others are relevant to all classes. This was intentional as it attempts to give some features more importance than others. Also due to the nature of how classes are generated, one class may overlap with another in its values for some attributes which would introduce noise to the data. All datasets have 10\% noise arbitrarily introduced.

The datasets generated are as follows:
\begin{itemize}
\item[•]\textbf{FY A} \\
This dataset was generated using the Conditional Generator with 4 classes, 10 relevant nominal features, 9 relevant numeric features, 10 irrelevant nominal features and 11 irrelevant numeric features. Nominal features have at most 10 values and numeric features have at most 5 divisions, therefore a maximum of 3 accepted ranges.

\item[•]\textbf{FY A Drift}\\
This dataset is generated using the Conditional Generator using the same parameters as FY A, but with a sudden feature drift occurring after 250,000 instances in the stream.

The first stream concept is the same as the concept in the FY A dataset. The second concept has 4 classes, 10 relevant nominal features, 10 relevant numeric features, 10 irrelevant nominal features and 10 irrelevant numeric features. Nominal features in the second concept have at most 10 values and numeric features have at most 5 divisions, therefore a maximum of 3 accepted ranges. The relevant features between concepts are different and the accepted values and ranges are also different.

\item[•]\textbf{FY B}\\
This dataset contains 4 classes, 8 relevant nominal features, 5 relevant numeric features, 52 irrelevant nominal features and 55 irrelevant numeric features. Nominal features have at most 10 values and numeric features have at most 5 divisions, therefore a maximum of 3 accepted ranges.

\item[•]\textbf{FY B Drift}\\
Dataset generated with the same parameters as the FY B dataset, but with a sudden feature drift occurring after 250,000 instances in the stream. 

The first stream concept is the same as FY B and the second concept has 10 classes, 9 relevant nominal features, 10 relevant numeric features, 50 irrelevant nominal features and 51 irrelevant numeric features. Nominal features in the second concept have at most 10 values and numeric features have at most 5 divisions, therefore a maximum of 3 accepted ranges. The relevant features between concepts are different and the accepted values and ranges are also different.

\item[•]\textbf{FY C}\\
This dataset contains 10 classes, 3 relevant nominal features, 3 relevant numeric features, 51 irrelevant nominal features and 50 irrelevant numeric features. Nominal features have at most 25 values and numeric features have at most 25 divisions, therefore a maximum of 13 accepted ranges. A sudden feature drift occurs after 250,000 instances but the number of relevant and irrelevant features remain the same.

\item[•]\textbf{FY D}\\
This dataset contains two feature drifts occurring at 200,000 instances and 400,00 instances. Nominal features have at most 25 values and numeric features have at most 25 divisions, therefore a maximum of 13 accepted ranges. 

The first Concept has 10 relevant nominal features, 10 relevant numeric features, 50 irrelevant nominal features, and 50 irrelevant numeric features. The second concept has 10 relevant nominal features, 8 relevant numeric features, 50 irrelevant nominal features, and 52 irrelevant numeric features. The third concept has 10 relevant nominal features, 7 relevant numeric features, 50 irrelevant nominal features, and 52 irrelevant numeric features.
\end{itemize}

\section{Results measured}
We were most interested in the prediction accuracy and computation time of experiments. We recorded both prediction accuracy over instances at every 10,000 instance intervals and the overall mean prediction accuracy. Computation time was based on the time it took for the classifier to finish classifying the entire dataset and was measured in seconds. 

The serialised size of the model generated in MOA was measured in bytes. This was the main measure for memory usage. Serialisation was done using the Serializable interface in Java. One key point to note is that this implementation is somewhat dependent on the JVM implementation and therefore can give different results depending on the operating system and JVM version.

We also measured RAM hours which gives us a measure of model cost. 1 RAM Hour equates to 1 GB of RAM dispensed per hour of processing as defined by \citet{bifet2010fast}.